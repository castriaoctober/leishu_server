{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc5453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "# 4月9日\n",
    "def convert_to_boolean_mode(keyword: str) -> str:\n",
    "    \"\"\"\n",
    "    将用户输入的关键词转换为 MySQL Boolean Mode 格式。\n",
    "    例如：\"NOT 王 AND 李 OR 张\" → \"-王 +李 张\"\n",
    "    \"\"\"\n",
    "    keyword = keyword.replace(\"(\", \"\").replace(\")\", \"\").upper()\n",
    "    # 将 NOT 替换为负号\n",
    "    keyword = re.sub(r'\\bNOT\\b\\s*', '-', keyword)\n",
    "    # 保留 AND（用于前缀加号）\n",
    "    keyword = re.sub(r'\\bAND\\b', 'AND', keyword)\n",
    "    # 移除 OR（MySQL 中空格相当于 OR）\n",
    "    keyword = re.sub(r'\\bOR\\b', '', keyword)\n",
    "    tokens = keyword.split()\n",
    "\n",
    "    converted = []\n",
    "    prev_token = \"\"\n",
    "    for token in tokens:\n",
    "        if token == \"AND\":\n",
    "            prev_token = \"AND\"\n",
    "        elif token.startswith('-'):\n",
    "            # 已经是 NOT 前缀的，直接添加\n",
    "            converted.append(token)\n",
    "            prev_token = \"\"\n",
    "        else:\n",
    "            # AND 后的词添加前缀 \"+\"，否则直接添加\n",
    "            converted.append(f\"+{token}\" if prev_token == \"AND\" else token)\n",
    "            prev_token = \"\"\n",
    "    return \" \".join(converted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a60b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4月9日\n",
    "def convert_to_boolean_mode(keyword: str) -> str:\n",
    "    \"\"\"\n",
    "    将用户输入的关键词转换为 MySQL Boolean Mode 格式。\n",
    "    例如：\"NOT 王 AND 李 OR 张\" → \"-王 +李 张\"\n",
    "    \"\"\"\n",
    "    keyword = keyword.replace(\"(\", \"\").replace(\")\", \"\").upper()\n",
    "    keyword = re.sub(r'\\bNOT\\b\\s*', '-', keyword)\n",
    "    keyword = re.sub(r'\\bAND\\b', 'AND', keyword)\n",
    "    keyword = re.sub(r'\\bOR\\b', '', keyword)\n",
    "    tokens = keyword.split()\n",
    "\n",
    "    converted = []\n",
    "    prev_token = \"\"\n",
    "    for token in tokens:\n",
    "        if token == \"AND\":\n",
    "            prev_token = \"AND\"\n",
    "        elif token.startswith('-'):\n",
    "            converted.append(token)\n",
    "            prev_token = \"\"\n",
    "        else:\n",
    "            converted.append(f\"+{token}\" if prev_token == \"AND\" else token)\n",
    "            prev_token = \"\"\n",
    "    return \" \".join(converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52824f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4月9日\n",
    "def build_where_clause_grouped(conditions):\n",
    "    \"\"\"\n",
    "    根据 OR 逻辑将搜索条件分组，每个组内按列名再分组，并根据 AND/NOT 构造最终的 WHERE 子句。\n",
    "    \"\"\"\n",
    "\n",
    "    def split_conditions_by_or(conditions):\n",
    "        \"\"\"根据 OR 逻辑将条件切分为多个逻辑块\"\"\"\n",
    "        blocks = []\n",
    "        current_block = []\n",
    "\n",
    "        for i, cond in enumerate(conditions):\n",
    "            logic = cond[\"logic\"].strip().upper()\n",
    "            if i == 0:\n",
    "                current_block.append(cond)\n",
    "            elif logic == \"OR\":\n",
    "                blocks.append(current_block)\n",
    "                current_block = [cond]\n",
    "            else:\n",
    "                current_block.append(cond)\n",
    "\n",
    "        if current_block:\n",
    "            blocks.append(current_block)\n",
    "\n",
    "        return blocks\n",
    "\n",
    "    def process_block(block):\n",
    "        \"\"\"处理单个逻辑块：按列分组后，根据 AND/NOT 构造 MATCH 子句\"\"\"\n",
    "        grouped = defaultdict(list)\n",
    "\n",
    "        for cond in block:\n",
    "            grouped[cond[\"column\"]].append((cond[\"logic\"].upper().strip(), cond[\"keyword\"]))\n",
    "\n",
    "        sub_queries = []\n",
    "\n",
    "        for col, cond_list in grouped.items():\n",
    "            col_alias = {\n",
    "                \"doc_title\": \"d.doc_title\",\n",
    "                \"author_name\": \"a.author_name\",\n",
    "                \"title_name\": \"t.title_name\",\n",
    "                \"full_text\": \"f.full_text\"\n",
    "            }.get(col)\n",
    "\n",
    "            if not col_alias:\n",
    "                continue\n",
    "\n",
    "            clauses = []\n",
    "            for i, (logic, keyword) in enumerate(cond_list):\n",
    "                boolean_keyword = convert_to_boolean_mode(keyword)\n",
    "                base = f\"MATCH({col_alias}) AGAINST('{boolean_keyword}' IN BOOLEAN MODE)\"\n",
    "\n",
    "                if i == 0:\n",
    "                    if logic == \"NOT\":\n",
    "                        clauses.append(f\"NOT {base}\")\n",
    "                    else:\n",
    "                        clauses.append(base)\n",
    "                else:\n",
    "                    if logic == \"AND\":\n",
    "                        clauses.append(f\"AND {base}\")\n",
    "                    elif logic == \"NOT\":\n",
    "                        clauses.append(f\"AND NOT {base}\")\n",
    "                    # OR 已在外层处理，此处忽略\n",
    "\n",
    "            if clauses:\n",
    "                sub_queries.append(\" \".join(clauses))\n",
    "\n",
    "        return \" AND \".join(sub_queries)\n",
    "\n",
    "    # 1. 按 OR 逻辑拆分成多个逻辑块\n",
    "    blocks = split_conditions_by_or(conditions)\n",
    "\n",
    "    # 2. 对每个块生成对应的 WHERE 子句\n",
    "    where_clauses = []\n",
    "    for block in blocks:\n",
    "        clause = process_block(block)\n",
    "        if clause:\n",
    "            where_clauses.append(f\"({clause})\")\n",
    "\n",
    "    # 3. 将所有子句用 OR 连接成最终 WHERE 子句\n",
    "    return \" OR \".join(where_clauses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756fdcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4月9日\n",
    "def build_sql_with_joins(conditions):\n",
    "    from_clause = \"FROM documents d\"\n",
    "    joins = []\n",
    "    select_fields = [\"d.*\"]\n",
    "\n",
    "    # 获取所有使用到的列\n",
    "    used_columns = {cond[\"column\"] for cond in conditions}\n",
    "\n",
    "    # 如果使用到作者信息，添加相关的连接\n",
    "    if \"author_name\" in used_columns:\n",
    "        joins.append(\"LEFT JOIN document_author_links dal ON dal.doc_id = d.doc_id\")\n",
    "        joins.append(\"LEFT JOIN authors a ON a.author_id = dal.author_id\")\n",
    "        select_fields.append(\"a.*, dal.*\")\n",
    "\n",
    "    # 如果使用到标题，添加 titles 表连接\n",
    "    if \"title_name\" in used_columns:\n",
    "        joins.append(\"LEFT JOIN titles t ON t.doc_id = d.doc_id\")\n",
    "        select_fields.append(\"t.*\")\n",
    "\n",
    "    # 如果使用到全文，添加 full_text_1 表连接\n",
    "    if \"full_text\" in used_columns:\n",
    "        joins.append(\"LEFT JOIN full_text_1 f ON f.doc_id = d.doc_id\")\n",
    "        select_fields.append(\"f.*\")\n",
    "\n",
    "    # 生成 WHERE 条件子句\n",
    "    where_clause = build_where_clause_grouped(conditions)\n",
    "\n",
    "    # 基于 AND 的逻辑分组分析\n",
    "    def get_and_clusters(conditions):\n",
    "        clusters = []\n",
    "        current_cluster = []\n",
    "\n",
    "        for i, cond in enumerate(conditions):\n",
    "            if i == 0 or cond[\"logic\"].upper().strip() == \"AND\":\n",
    "                current_cluster.append(cond[\"column\"])\n",
    "            else:\n",
    "                if current_cluster:\n",
    "                    clusters.append(set(current_cluster))\n",
    "                current_cluster = [cond[\"column\"]]\n",
    "        if current_cluster:\n",
    "            clusters.append(set(current_cluster))\n",
    "        return clusters\n",
    "\n",
    "    clusters = get_and_clusters(conditions)\n",
    "\n",
    "    # 如果在同一个 AND 组中同时使用 full_text 和 title_name，则需要用 title_id 关联\n",
    "    needs_title_id_match = any({\"full_text\", \"title_name\"}.issubset(cluster) for cluster in clusters)\n",
    "\n",
    "    if needs_title_id_match:\n",
    "        extra_condition = \"f.title_id = t.title_id\"\n",
    "        if where_clause:\n",
    "            where_clause += f\" AND {extra_condition}\"\n",
    "        else:\n",
    "            where_clause = extra_condition\n",
    "\n",
    "    # 组装最终 SQL 语句\n",
    "    sql = f\"SELECT DISTINCT {', '.join(select_fields)}\\n{from_clause}\"\n",
    "    if joins:\n",
    "        sql += \"\\n\" + \"\\n\".join(joins)\n",
    "    if where_clause:\n",
    "        sql += \"\\nWHERE \" + where_clause\n",
    "    sql += \"\\nLIMIT 100;\"\n",
    "\n",
    "    return sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c6e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4月9日\n",
    "def fetch_extra_fields_by_doc_id(conn, doc_id, title_id=None):\n",
    "    \"\"\"\n",
    "    基于 doc_id 获取代表性信息；如果提供了 title_id，则优先使用 title_id 获取 full_text 段落摘要。\n",
    "    \"\"\"\n",
    "    enriched = {}\n",
    "\n",
    "    with conn.cursor() as cursor:\n",
    "        # 获取 title_name（最多两个标题，用于判断是否添加“等”）\n",
    "        cursor.execute(\"SELECT title_name FROM titles WHERE doc_id = %s LIMIT 2\", (doc_id,))\n",
    "        rows = cursor.fetchall()\n",
    "        if rows:\n",
    "            title = rows[0][\"title_name\"]\n",
    "            if len(rows) > 1:\n",
    "                title += \" 等\"\n",
    "            enriched[\"title_name\"] = title\n",
    "        else:\n",
    "            enriched[\"title_name\"] = None\n",
    "\n",
    "        # 获取 author_name 和 author_org（最多两位作者，判断是否添加“等”）\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT a.author_name, a.author_org\n",
    "            FROM authors a\n",
    "            JOIN document_author_links dal ON dal.author_id = a.author_id\n",
    "            WHERE dal.doc_id = %s\n",
    "            LIMIT 2\n",
    "        \"\"\", (doc_id,))\n",
    "        rows = cursor.fetchall()\n",
    "        if rows:\n",
    "            name = rows[0][\"author_name\"]\n",
    "            if len(rows) > 1:\n",
    "                name += \" 等\"\n",
    "            enriched[\"author_name\"] = name\n",
    "            enriched[\"author_org\"] = rows[0][\"author_org\"]\n",
    "        else:\n",
    "            enriched[\"author_name\"] = None\n",
    "            enriched[\"author_org\"] = None\n",
    "\n",
    "        # 获取 full_text（优先使用 title_id，否则使用 doc_id），截取前100字加“···”\n",
    "        if title_id:\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT full_text \n",
    "                FROM full_text_1 \n",
    "                WHERE title_id = %s \n",
    "                ORDER BY full_text_order ASC \n",
    "                LIMIT 1\n",
    "            \"\"\", (title_id,))\n",
    "        else:\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT full_text \n",
    "                FROM full_text_1 \n",
    "                WHERE doc_id = %s \n",
    "                ORDER BY full_text_order ASC \n",
    "                LIMIT 1\n",
    "            \"\"\", (doc_id,))\n",
    "\n",
    "        row = cursor.fetchone()\n",
    "        if row and row[\"full_text\"]:\n",
    "            enriched[\"full_text\"] = row[\"full_text\"][:100] + \"···\"\n",
    "        else:\n",
    "            enriched[\"full_text\"] = None\n",
    "\n",
    "    return enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7d5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4月9日\n",
    "def enrich_results_with_missing_info(conn, results):\n",
    "    \"\"\"\n",
    "    如果查询结果中缺少必要字段，则根据 doc_id 补充这些字段的代表值。\n",
    "    \"\"\"\n",
    "    must_fields = [\"title_name\", \"author_name\", \"author_org\", \"full_text\"]\n",
    "    enriched_results = []\n",
    "\n",
    "    for row in results:\n",
    "        doc_id = row[\"doc_id\"]\n",
    "\n",
    "        # 检查哪些必要字段不存在于当前结果行中\n",
    "        missing_fields = [field for field in must_fields if field not in row]\n",
    "\n",
    "        if missing_fields:\n",
    "            # 获取补充数据，只更新缺失的字段\n",
    "            extra_data = fetch_extra_fields_by_doc_id(conn, doc_id)\n",
    "            for key in missing_fields:\n",
    "                row[key] = extra_data.get(key)\n",
    "\n",
    "        enriched_results.append(row)\n",
    "\n",
    "    return enriched_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9090d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"doc_title\": \"《永乐大典》\",\n",
      "  \"categoty_type\": \"\",\n",
      "  \"doc_specific_category\": \"综合性类书\",\n",
      "  \"doc_style\": \"类事\",\n",
      "  \"doc_theme\": \"百科\",\n",
      "  \"author_name\": \"解縉\",\n",
      "  \"author_org\": \"明朝翰林院\",\n",
      "  \"role\": \"总纂\",\n",
      "  \"title_name\": \"永樂大典卷九百 等\",\n",
      "  \"full_text\": \"敬齋古今黈···\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pymysql # 用的是不是Django？\n",
    "import json\n",
    "\n",
    "conn = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='前端同学请输入自己的数据库密码',\n",
    "    db='leishu_yongle',\n",
    "    charset='utf8mb4',\n",
    "    cursorclass=pymysql.cursors.DictCursor\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 这里就是从前端获取JSON查询数据的部分\n",
    "# 请按照下面格式获取数据（以author_name为例）\n",
    "# search_conditions = [\n",
    "#     {\"column\": \"author_name\", \"keyword\": \"姚廣孝\", \"logic\": \"\"},\n",
    "#     {\"column\": \"full_text\", \"keyword\": \"大漠孤烟直\", \"logic\": \"\"},\n",
    "#     ]\n",
    "\n",
    "\n",
    "\n",
    "sql = build_sql_with_joins(search_conditions)\n",
    "\n",
    "try:\n",
    "    cursor.execute(sql)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    final_results = enrich_results_with_missing_info(conn, results)\n",
    "    output_fields = [\"doc_title\",\"categoty_type\",\"doc_specific_category\",\"doc_style\",\"doc_theme\",\"author_name\",\"author_org\",\"role\",\"title_name\",\"full_text\"]\n",
    "\n",
    "    for row in results:\n",
    "        filtered = {field: row.get(field, \"\") for field in output_fields}\n",
    "        print(json.dumps(filtered, ensure_ascii=False, indent=2, default=str))\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
